

### Why estimate $f$ 

1. Prediction: 
2. Inference: Know relation between predictor and response, how the change in predictor affect the response. 

### Approaches to estimate $f$

#### 1. Parametric Methods

1. First make assumption about the form of $f$ (e.g. linear).
2. _Fit_  or _train_ the data for the assumed form of $\hat{f}$. 

Simplest for is linear model

$$ f(\mathit{X}) = \beta_0 + \beta_1\mathit{X}_2 + \beta\mathit{X}_3 + \ldots + \beta_p\mathit{X}_p  $$

Where $\beta_j$ are the _parameters_ (parametric) we estimate and $j= 1, 2, 3, \ldots, p$ , where $p$ is the number of predictor in the dataset.


#### 2. Non-Parametric Methods

1. Does not assume a form of $f$ giving it the edge to be more accurate in some cases. But it requires a way larger observation to work.

---
- In inference case, a more restricted models (parametric) give us clear relation between response and predictors (interpretability) . Where we are interested in the prediction alone, non flexible models (Non-parametric) can give us the value we want to predict alone. 
- Each approach is valid, it depends on the problem at hand. 
- Some time restrictive model produce more accurate result than less restrictive models due to overfitting. 

#### Selection of Statistical Learning Methods

- It usually depends on the response type $y$ either quantitative (numerical) or qualitative (categorical). 
- For example, one might use linear regression for quantitative predictors, or logistic regression (classification) for qualitative reponses. 